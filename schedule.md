| Date 	| Topics (tentative)  	| Papers to present  	|  	|  	| Review Forms 	|
|-	|-	|-	|-	|-	|-	|
|  	|  	| Paper 1 	| Paper 2 	| Paper 3 	|  	|
| 8/26 	| Introduction [slides](docs/intro.pdf) 	| N/A 	|  	|  	| N/A 	|
| 9/2 	| Efficient training - I (DNN Training) 	| [Capuchin: Tensor-based GPU Memory Management for Deep Learning](https://dl.acm.org/doi/10.1145/3373376.3378505) 	| [Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks](https://openreview.net/forum?id=BJxsrgStvr) 	| [DeltaGrad: Rapid retraining of machine learning models](https://icml.cc/virtual/2020/poster/5915)  	| [form](https://forms.gle/s2FtDmDoYmfHJmJq6) 	|
| 9/9 	| Efficient training - II (GNN Training) 	| [Deep graph library: Towards efficient and scalable deep learning on graphs](https://arxiv.org/abs/1909.01315) 	| [GraphSAINT: Graph Sampling Based Inductive Learning Method](https://arxiv.org/pdf/1907.04931.pdf) 	| [VLDB'19][AliGraph: A Comprehensive Graph Neural Network Platform](http://www.vldb.org/pvldb/vol12/p2094-zhu.pdf) 	| [form](https://forms.gle/6MkNu6dL3GUFBjoU8) 	|
| 9/16 	| Distributed training  	| [Supporting Very Large Models using Automatic Dataflow Graph Partitioning](http://www.news.cs.nyu.edu/~jinyang/pub/tofu-eurosys19.pdf) 	| [Prague: High-Performance Heterogeneity-Aware Asynchronous Decentralized Training](https://dl.acm.org/doi/abs/10.1145/3373376.3378499) 	| [A generic communication scheduler for distributed DNN training acceleration](https://dl.acm.org/doi/10.1145/3341301.3359642) 	| [form](https://forms.gle/aS9CMhfUaHddXNpHA) 	|
| 9/23 	| Automated Discovery of Machine Learning Optimizations 	| [TASO: Optimizing Deep Learning Computation with Automated Generation of Graph Substitutions](https://cs.stanford.edu/~zhihao/papers/sosp19.pdf) 	| [Beyond Data and Model Parallelism for Deep Neural Networks](https://cs.stanford.edu/~zhihao/papers/sysml19a.pdf) 	| N/A 	| [form](https://forms.gle/7VtaaqE9tHEjdiLQA) 	|
| 9/30 	| Efficient inference - I (Resource Management) 	| [GRNN: Low-Latency and Scalable RNN Inference on GPUs](https://dl.acm.org/doi/pdf/10.1145/3302424.3303949) 	| [MLSys'20][Willump: A Statistically-Aware End-to-end Optimizer for Machine Learning Inference](https://arxiv.org/pdf/1906.01974.pdf) 	| [EuroSys'19][Î¼Layer: Low Latency On-Device Inference Using Cooperative Single-Layer Acceleration and Processor-Friendly Quantization](https://dl.acm.org/doi/10.1145/3302424.3303950) 	| [form](https://forms.gle/CtDL7gVF6nWjsL2t9) 	|
| 10/7 	| Efficient inference - II (Multi-Tasking) 	| [MLSys'20] [Salus: Fine-Grained GPU Sharing Primitives for Deep Learning Applications](https://proceedings.mlsys.org/paper/2020/file/f7177163c833dff4b38fc8d2872f1ec6-Paper.pdf) 	| [MobiSys'20][Fast and Scalable In-memory Deep Multitask Learning via Neural Weight Virtualization](https://dl.acm.org/doi/abs/10.1145/3386901.3388947) 	| [rtss'19] [Pipelined Data-Parallel CPU/GPU Scheduling for Multi-DNN Real-Time Inference](https://intra.ece.ucr.edu/~hyoseung/pdf/rtss19-dart.pdf) 	| [form](https://forms.gle/Q5XfsckMFzjuMzfr7) 	|
| 10/14 	| Efficient inference - III (Compression) 	| [ICML'20][Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers](https://icml.cc/virtual/2020/poster/6828) 	| [ICML'20][Boosting Deep Neural Network Efficiency with Dual-Module Inference](https://icml.cc/virtual/2020/poster/6670) 	| [ICLR'20][Comparing Rewinding and Fine-tuning in Neural Network Pruning](https://openreview.net/forum?id=S1gSj0NKvB)  	| [form](https://forms.gle/yy4zsvtsN8gPSNP87) 	|
| 10/21 	| ML Robustness 	| [ICML'20][Understanding and Mitigating the Tradeoff between Robustness and Accuracy](https://icml.cc/virtual/2020/poster/6801)  	| [ICML'20][More Data Can Expand The Generalization Gap Between Adversarially Robust and Standard Models](https://icml.cc/virtual/2020/poster/5943) 	| [ICLR'20][Talk][Adversarial Training and Provable Defenses: Bridging the Gap ](https://openreview.net/forum?id=SJxSDxrKDr) 	| [form](https://forms.gle/YRoPM8Ht37qyBDcy8) 	|
| 10/28 	| ML for System-I (ml systems) 	| [asplos'20][FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System](https://dl.acm.org/doi/abs/10.1145/3373376.3378508?casa_token=YWcNPnp03fsAAAAA:Xo3RLkiykJSN8H70bsiQre-0hI20U5Sgu3_LYbsIqOSCsi8aBay18752gyZSFvYVlG34pTjrYyHm) 	| [Learning to Optimize Tensor Programs](https://papers.nips.cc/paper/7599-learning-to-optimize-tensor-programs.pdf) 	| [Learning to Optimize Halide with Tree Search and Random Programs](https://halide-lang.org/papers/halide_autoscheduler_2019.pdf) 	| [form](https://forms.gle/EngGHDUe68VdwnMx7) 	|
| 11/4 	| ML for System-II (programming systems) 	| [ICLR'18][Learning to Represent Programs with Graphs](https://arxiv.org/abs/1711.00740) 	| [MLsys'20][AutoPhase: Juggling HLS Phase Orderings in Random Forests with Deep Reinforcement Learning](https://proceedings.mlsys.org/paper/2020/file/4e732ced3463d06de0ca9a15b6153677-Paper.pdf) 	| [ICML'20] [An Imitation Learning Approach for Cache Replacement](https://icml.cc/virtual/2020/poster/6044) 	| [form](https://forms.gle/yCKh8bs3tL79LgxVA)  	|
| 11/11 	| TVM: An automated deep learning compiler 	| [TVM: An Automated End-to-End Optimizing Compiler for Deep Learning](https://arxiv.org/abs/1802.04799) 	| N/A 	| N/A 	| [form](https://forms.gle/Kd3Mw22Vc1nw2BpY7) 	|
| 11/18 	| project presentations 	| N/A 	|  	|  	| N/A 	|